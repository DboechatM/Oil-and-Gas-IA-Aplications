{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b96445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'ESP', 'lamda1', 'x1'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = loadmat('dispersionpoints.mat')\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557f8e2",
   "metadata": {},
   "source": [
    "## Monte Carlo CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fb28541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Generator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "from sklearn.utils.validation import indexable, _num_samples\n",
    "\n",
    "\n",
    "class MonteCarloCV(_BaseKFold):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_splits: int,\n",
    "                 train_size: float,\n",
    "                 test_size: float,\n",
    "                 gap: int = 0):\n",
    "        \"\"\"\n",
    "        Monte Carlo Cross-Validation\n",
    "\n",
    "        Holdout applied in multiple testing periods\n",
    "        Testing origin (time-step where testing begins) is randomly chosen according to a monte carlo simulation\n",
    "\n",
    "        :param n_splits: (int) Number of monte carlo repetitions in the procedure\n",
    "        :param train_size: (float) Train size, in terms of ratio of the total length of the series\n",
    "        :param test_size: (float) Test size, in terms of ratio of the total length of the series\n",
    "        :param gap: (int) Number of samples to exclude from the end of each train set before the test set.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_splits = n_splits\n",
    "        self.n_samples = -1\n",
    "        self.gap = gap\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.train_n_samples = 0\n",
    "        self.test_n_samples = 0\n",
    "\n",
    "        self.mc_origins = []\n",
    "\n",
    "    def split(self, X, y=None, groups=None) -> Generator:\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where `n_samples` is the number of samples\n",
    "            and `n_features` is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        self.n_samples = _num_samples(X)\n",
    "\n",
    "        self.train_n_samples = int(self.n_samples * self.train_size) - 1\n",
    "        self.test_n_samples = int(self.n_samples * self.test_size) - 1\n",
    "\n",
    "        # Make sure we have enough samples for the given split parameters\n",
    "        if self.n_splits > self.n_samples:\n",
    "            raise ValueError(\n",
    "                f'Cannot have number of folds={self.n_splits} greater'\n",
    "                f' than the number of samples={self.n_samples}.'\n",
    "            )\n",
    "        if self.train_n_samples - self.gap <= 0:\n",
    "            raise ValueError(\n",
    "                f'The gap={self.gap} is too big for number of training samples'\n",
    "                f'={self.train_n_samples} with testing samples={self.test_n_samples} and gap={self.gap}.'\n",
    "            )\n",
    "\n",
    "        indices = np.arange(self.n_samples)\n",
    "\n",
    "        selection_range = np.arange(self.train_n_samples + 1, self.n_samples - self.test_n_samples - 1)\n",
    "\n",
    "        self.mc_origins = \\\n",
    "            np.random.choice(a=selection_range,\n",
    "                             size=self.n_splits,\n",
    "                             replace=True)\n",
    "\n",
    "        for origin in self.mc_origins:\n",
    "            if self.gap > 0:\n",
    "                train_end = origin - self.gap + 1\n",
    "            else:\n",
    "                train_end = origin - self.gap\n",
    "            train_start = origin - self.train_n_samples - 1\n",
    "\n",
    "            test_end = origin + self.test_n_samples\n",
    "\n",
    "            yield (\n",
    "                indices[train_start:train_end],\n",
    "                indices[origin:test_end],\n",
    "            )\n",
    "\n",
    "    def get_origins(self) -> List[int]:\n",
    "        return self.mc_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d443654",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 6.68424850e-04, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.33633598e-03, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        8.26254997e-01, 1.00671452e+00, 1.02473435e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        8.26877362e-01, 1.00802210e+00, 1.02609304e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        8.27499826e-01, 1.00933069e+00, 1.02745084e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "        0.00000000e+000, 5.06806211e-253, 0.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "        0.00000000e+000, 1.01322291e-252, 0.00000000e+000],\n",
       "       ...,\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "        4.06197666e-001, 4.24970087e-001, 2.54093240e-001],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "        4.06926305e-001, 4.25343292e-001, 2.54330546e-001],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "        4.07653070e-001, 4.25716238e-001, 2.54567746e-001]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lambda = data['lamda1']\n",
    "\n",
    "#First and last run preview\n",
    "display(data_lambda[:,:,0])\n",
    "display(data_lambda[:,:,99])\n",
    "\n",
    "#tensor flatten and stack\n",
    "#lambda1 = data_lambda.transpose(1,2,0).reshape(-1,data_lambda.shape[1])\n",
    "#display(lambda1)\n",
    "#display(lambda1.shape)\n",
    "\n",
    "#base on\n",
    "#https://stackoverflow.com/questions/35992458/convert-reshape-3d-matrix-to-a-2d-matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "300f77e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03  , 0.0298, 0.0296, 0.0294, 0.0292, 0.029 , 0.0288, 0.0286,\n",
       "        0.0284, 0.0282, 0.028 , 0.0278, 0.0276, 0.0274, 0.0272, 0.027 ,\n",
       "        0.0268, 0.0266, 0.0264, 0.0262, 0.026 , 0.0258, 0.0256, 0.0254,\n",
       "        0.0252, 0.025 , 0.0248, 0.0246, 0.0244, 0.0242, 0.024 , 0.0238,\n",
       "        0.0236, 0.0234, 0.0232, 0.023 , 0.0228, 0.0226, 0.0224, 0.0222,\n",
       "        0.022 , 0.0218, 0.0216, 0.0214, 0.0212, 0.021 , 0.0208, 0.0206,\n",
       "        0.0204, 0.0202, 0.02  , 0.0198, 0.0196, 0.0194, 0.0192, 0.019 ,\n",
       "        0.0188, 0.0186, 0.0184, 0.0182, 0.018 , 0.0178, 0.0176, 0.0174,\n",
       "        0.0172, 0.017 , 0.0168, 0.0166, 0.0164, 0.0162, 0.016 , 0.0158,\n",
       "        0.0156, 0.0154, 0.0152, 0.015 , 0.0148, 0.0146, 0.0144, 0.0142,\n",
       "        0.014 , 0.0138, 0.0136, 0.0134, 0.0132, 0.013 , 0.0128, 0.0126,\n",
       "        0.0124, 0.0122, 0.012 , 0.0118, 0.0116, 0.0114, 0.0112, 0.011 ,\n",
       "        0.0108, 0.0106, 0.0104, 0.0102]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1499, 66, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1499, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [3.00000e-03, 2.98000e-03, 2.96000e-03, ..., 1.06000e-03,\n",
       "        1.04000e-03, 1.02000e-03],\n",
       "       [6.00000e-03, 5.96000e-03, 5.92000e-03, ..., 2.12000e-03,\n",
       "        2.08000e-03, 2.04000e-03],\n",
       "       ...,\n",
       "       [4.48800e+00, 4.45808e+00, 4.42816e+00, ..., 1.58576e+00,\n",
       "        1.55584e+00, 1.52592e+00],\n",
       "       [4.49100e+00, 4.46106e+00, 4.43112e+00, ..., 1.58682e+00,\n",
       "        1.55688e+00, 1.52694e+00],\n",
       "       [4.49400e+00, 4.46404e+00, 4.43408e+00, ..., 1.58788e+00,\n",
       "        1.55792e+00, 1.52796e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Espessura\n",
    "ESP = data['ESP']\n",
    "print(ESP.shape)\n",
    "display(ESP)\n",
    "\n",
    "#Comprimento de onda normalizado\n",
    "display(data_lambda.shape)\n",
    "\n",
    "#frequências normalizadas\n",
    "x1 = data['x1']\n",
    "print(x1.shape)\n",
    "display(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d11e409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[1000,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0556b8a4",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Geração dos dados de treinamento e teste\n",
    "num_samples = 1000\n",
    "x_train = np.zeros((num_samples, 60, 60, 1))\n",
    "y_train = np.zeros((num_samples, 1))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Geração dos valores de entrada\n",
    "    input_data = np.array([[random.randint(10000, 20000), random.randint(50, 80), random.randint(50, 150)]])\n",
    "\n",
    "    # Transformação dos valores em uma matriz de imagem de 60x60\n",
    "    x_train[i] = input_data.reshape(60, 60, 1)\n",
    "\n",
    "    # Geração do valor de saída com base no método de Monte Carlo\n",
    "    y_train[i] = random.uniform(100, 200)\n",
    "\n",
    "# Separação dos dados em treinamento e validação\n",
    "val_percentage = 0.2\n",
    "val_size = int(num_samples * val_percentage)\n",
    "x_val = x_train[:val_size]\n",
    "y_val = y_train[:val_size]\n",
    "x_train = x_train[val_size:]\n",
    "y_train = y_train[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Transformação dos valores em uma matriz de imagem de 60x60\n",
    "input_data = np.array([[14900, 66, 100]])\n",
    "input_image = input_data.reshape(60, 60, 1)\n",
    "\n",
    "# Previsão do modelo\n",
    "prediction = model.predict(input_image)\n",
    "\n",
    "# Exibição do resultado\n",
    "print(\"O diâmetro previsto é: \", prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Adição da camada de convolução\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(60,60,1)))\n",
    "\n",
    "# Adição da camada de pooling\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# Adição de mais camadas de convolução e pooling (opcional)\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "\n",
    "# Adição da camada fully connected para classificação\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Adição do callback de early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, callbacks=[early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
